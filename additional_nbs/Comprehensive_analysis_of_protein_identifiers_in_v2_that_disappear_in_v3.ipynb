{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "879c5a9e-5103-41f4-8db0-bd9dcc640ea1",
   "metadata": {},
   "source": [
    "## (Technical) Comprehensive analysis of protein identifiers in hu.MAP 2.0 complexes that_disappear in hu.MAP 3.0 complexes\n",
    "\n",
    "Note that this notebook is labeled as **technical** as it will be interesting to most users. If you are interested in looking at differences for the proteins you are interested in, you'll most likely want to see the following instead (or at least initially):\n",
    "\n",
    "- [Highlight differences between hu.MAP 2.0 and hu.MAP 3.0 data](Highlight_differences_between_hu.MAP2_and_hu.MAP3_data.ipynb)\n",
    "- [Using snakemake to highlight differences between hu.MAP 2.0 and hu.MAP 3.0 data for multiple identifiers](Using_snakemake_to_highlight_differences_between_hu.MAP2_and_hu.MAP3_data_for_multiple_identifiers.ipynb)\n",
    "\n",
    "Only if after that, you are then trying to understand what is going on with the differences with Dataset-wide examination would then you be interested in this notebook as a way to start collecting information in more comprehensive way.  \n",
    "\n",
    "\n",
    "**Impetus of this technical notebook:**\n",
    "\n",
    "In the course of examining the hu.MAP 3.0 complexes for a complex of interest we noted that one of the proteins we knew to be important to the complex was lost in the hu.MAP 3.0 data, yet present in related complexes in the hu.MAP 2.0 data. In order to try to understand this better, we were curious to get a more global survey of proteins that went missing from related complexes in the hu.MAP 3.0 data. You may be in a similar situation with a protein you are interesyed in and want to explore in a comprehensive manner if your case is one of the rare instances of such a case or common to the hu.MAP 3.0 data. If so, you may want to see what was done here and adapt it further to look at your proteins of interest in relation to others.\n",
    "\n",
    "**Overview of this technical notebook:**\n",
    "\n",
    "- Note that it finds proteins 'ubiquitous' in hu.MAP 2.0 complexes, yet go missing in version 3.0 data. To be 'ubiquitous' the number of associated complexes has to be more than one. May be a strict criteria, but there were an adundance without applying that condition, and still indentified a substantial group even with applying that, and so probably not too strict at this time.  \n",
    "- Then it goes to another level and is more strict to identify the proteins that go missing entirely from version 3.0 data.\n",
    "- The last parts of the notebook look more broadly & directly at identifiers gone entirely in version 3 without regard to related complexes or how many times the protein occurs in version 2 data.\n",
    "\n",
    "The main script that supports this notebook carries out that first bullet item. It will take all the identifiers occuring in both v2 and v3 data and use those to query and see what 'companion' proteins associated 'ubiquitously' in the complexes in the Hu.MAP 2.0 data go missing in the Hu.MAP 3.0 data for **related** complexes. Then in an even more strict analysis, the script looks for identifiers from Hu.MAP 2.0 data entirely missing in Hu.MAP 3.0 data. Additional code in the notebook looks for identifiers from Hu.MAP 2.0 data entirely missing in Hu.MAP 3.0 data and examines how this relates to what the script looking at related complexes identfied.\n",
    "\n",
    "Many of the issues raised here are not fully explored at this time. (That is left to the reader as there are a lot of directions go in carrying this further. It revealed that others may be unfortunate as well and that though there is a lot of change in version 3 that represents improvement, it may have been too strict in processing. It at least highlights there is room for improvement with version 4.0.)         \n",
    "And the idea is that the collections generated will serve as a foundation to extend this Jupyter `.ipynb` to suit your curiousities in this more panoramic view of the version 3.0 dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c6d92-a991-49b0-840e-02408a13802f",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### Preparation: to save time get already-generated dictionaries \n",
    "\n",
    "To save time running the main script, get already-generated dictionaries containing details on the involved collection of indentifiers so that it isn't necessary to iterate on identifiers again to collect all that data from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3b7abcd-a215-4e46-b872-8f79338f903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "files_to_copy_to_here = [\n",
    "    'disappearing_identified_with_dict.pkl',\n",
    "    'disappeared_total_complexes_dict.pkl',\n",
    "    'v2_complexes_with_disappearing_dict.pkl',\n",
    "    'gone_entirely_in_3_identified_via_dict.pkl',\n",
    "    'gone_entirely_in_3_total_complexes_dict.pkl',\n",
    "    'v2_complexes_dict_for_gone_in_3.pkl'\n",
    "]\n",
    "#storage_path = \"additional_nbs/stored_additional_data/used_for_checking_shifting_n_disappearing/\" # if running from root\n",
    "storage_path = \"stored_additional_data/used_for_checking_shifting_n_disappearing/\"\n",
    "for fn in files_to_copy_to_here:\n",
    "    copyfile(f\"{storage_path}{fn}\", f\"./{fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e2880f-c473-404a-9c41-fb8d27af74bc",
   "metadata": {},
   "source": [
    "(Note: Delete that step to start with square one and generate dictonaries again. Or if already ran that step and now need to run the skipped steps again because the script `identify_id_going_missing_from_related_complexes_and_going_entirely_inV3_Data.py` has been edited, delete the file `disappearing_identified_with_dict.pkl` in the current working directory. That is enough to trigger running entirely and new files with pickled dictionaries will get made.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c2184b-0d4d-4712-b7b4-1d839e22247d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run -i identify_id_going_missing_from_related_complexes_and_going_entirely_inV3_Data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88a0dc7c-a851-4adb-9f9e-a70241d3e2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9574"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accessions_shared_by_both_2and3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3723d553-041d-453b-af0a-3f9b574533ea",
   "metadata": {},
   "source": [
    "Note to put this number of identifiers shared between version 2 & 3 of the data in better context, there's 9963 unique Uniprot accension indentifiers in hu.MAP2.0 data and 13769 in hu.MAP 3.0 data. (Those numbers come from the 'Standardizing_identifier_order_...' notebooks under the 'standardizing_initial_data\n",
    "' directory.) That is a substantial increase.  \n",
    "And we need to bear in mind this entire notebook is only dealing with those that also occur in hu.MAP2.0 data and not those gained beyond that in hu.MAP 3.0 data.\n",
    "\n",
    "With that script run, we can assign some variables to make it easier to handle some of what was generated later. For example, we need to make a Python set object out of the list of keys for using Python's 'set math' later. The next cell will do that for two of the main groups of items it made. (We actually won't use again the lists the next cell makes, but I wanted to make it clear that is what it is being used in the conversion to a `set` object. Of further note, is that nothing is being dropped in the conversion. Often `set()` is used on lists to filter the items to unique occurences. That is not what is happening here. That can be shown by running `assert len(disappearing_identified_with_dict.keys()) == len(set(disappearing_identified_with_dict.keys()))` and `assert len(gone_entirely_in_3_identified_via_dict.keys()) == len(set(gone_entirely_in_3_identified_via_dict.keys()))` to verify no filtering takes place, just typecasting.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0a636d-564b-4dc6-9cdd-3868c03e1d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(disappearing_identified_with_dict.keys()) == len(set(disappearing_identified_with_dict.keys()))\n",
    "assert len(gone_entirely_in_3_identified_via_dict.keys()) == len(set(gone_entirely_in_3_identified_via_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "304d4cbd-3b4e-4fe7-b95d-38b380298957",
   "metadata": {},
   "outputs": [],
   "source": [
    "ubiquitous_disappearing_list = disappearing_identified_with_dict.keys()\n",
    "ubiquitous_disappearing_set = set(disappearing_identified_with_dict.keys())\n",
    "\n",
    "gone_entirely_in_3_list = gone_entirely_in_3_identified_via_dict.keys()\n",
    "gone_entirely_in_3_set = set(gone_entirely_in_3_identified_via_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a885df5b-7f44-4aa3-98a2-9618f94052b2",
   "metadata": {},
   "source": [
    "With the script run and some preliminary preparations for building on the details of what was collected by the script, we are ready to finally look at something interesting, the total number of 'ubiquitous', 'companion' proteins that go disappearing from related complexes when going from hu.MAP 2.0 data to hu.MAP 3.0 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1024e7d-4263-4b32-8a86-60ee11624de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2055"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(disappearing_identified_with_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b51c24-d583-400d-b1e0-573d4194a0bd",
   "metadata": {},
   "source": [
    "2065 related to 'ubiquitous' complex members seem to go missing from what are expected to be 'related' complexes. (This doesn't mean they go missing entirely though!)\n",
    "\n",
    "This seems substantial and probably gives some intial indication of the shifting or refinement that occurs between versions 2 and 3 of the hu.MAP data. This also may be higher than expected because if the shifting / refiniement is taking place, what is 'related' may need to shift in concept. And while that may be true, this programmatic way to highlight cases of proteins in version 2 being dramatically altered isn't meant to address that bigger notion. We just want to gauge what has changed and collect the associated details.\n",
    "\n",
    "You can look at individual examples like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4ba4738-b0bf-4e7f-8237-80ad9b5a3eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q9Y4W2', 'Q5SY16', 'Q9H4L4', 'Q9BV38']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disappearing_identified_with_dict['Q9NXF1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8309bf5a-01cf-4fc9-9570-3545686e45bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disappeared_total_complexes_dict['Q9NXF1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93319c51-9ac5-41c6-b3a9-56395fe51622",
   "metadata": {},
   "source": [
    "Looking at the list of what identifiers helped highlight `Q9NXF1` , we see `['Q9Y4W2', 'Q5SY16', 'Q9H4L4', 'Q9BV38']`.\n",
    "Each of those is known to be related to a known complext and so it is interesting that the identifier also known to be in that complex is lost in version 3 data while these related ones occur in version 2 data all together. known to be related are all in version 3 data but are lacking `Q9NXF1` in these related complexes.  \n",
    "\n",
    "So seems obvious someone interested in `Q9NXF1` and the related Five Friends of Methylated CHTOP (5FMC) complex\" would be wondering why gone in version 3 data and questioning 'improvement' at cost of what look to be good ones being lost.\n",
    "\n",
    "I will suggest though you not to bother doing that type of analysis for what you are interested in. While looking at individual ones this way may be sufficient for your needs, I would hold off on doing this much for individuals as tabular data will be made with this and more below. And the derivatives of that will be better for exploring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e272319-1dff-495e-8671-2f7b4826a587",
   "metadata": {},
   "source": [
    "We'll save those Python dictionary as text so that it can be perused if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c783c0a-eff2-45c6-bc48-88740ab6c8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'disappearing_identified_with_dict' (dict) to file 'disappearing_identified_with_dict.txt'.\n",
      "Writing 'disappeared_total_complexes_dict' (dict) to file 'disappeared_total_complexes_dict.txt'.\n"
     ]
    }
   ],
   "source": [
    "%store disappearing_identified_with_dict >disappearing_identified_with_dict.txt\n",
    "%store disappeared_total_complexes_dict >disappeared_total_complexes_dict.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653b1ab2-c41f-4159-9493-a0213f4a836d",
   "metadata": {},
   "source": [
    "Before going on to look more at what the script run above identified from among the complexes as 'ubiquotous' yet gone entirely in version 3 data, we'll display some of the data collected already in more combined & manageable form. This code in the next cell will make a dataframe composed of what has already been gleaned. This will probably be the form you want to peruse things in if you are so inclined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0cd4cbd-b9bc-4e19-bdba-c6586648cadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_acc</th>\n",
       "      <th>number_of_complexes</th>\n",
       "      <th>assoc_complex_ids</th>\n",
       "      <th>associated_identifiers_in_expected_related_huMAP3_complexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q13137</td>\n",
       "      <td>3</td>\n",
       "      <td>00806, 06259, 06729</td>\n",
       "      <td>Q9NVV4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q9NXF1</td>\n",
       "      <td>4</td>\n",
       "      <td>00441, 03649, 06152, 06210</td>\n",
       "      <td>Q9Y4W2, Q5SY16, Q9H4L4, Q9BV38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q8NBF6</td>\n",
       "      <td>2</td>\n",
       "      <td>02970, 05289</td>\n",
       "      <td>Q6UXD5, Q9UBG0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P80108</td>\n",
       "      <td>2</td>\n",
       "      <td>02970, 05289</td>\n",
       "      <td>Q6UXD5, Q9UBG0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q96LR4</td>\n",
       "      <td>2</td>\n",
       "      <td>02970, 05289</td>\n",
       "      <td>Q6UXD5, Q9UBG0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>Q9Y3B1</td>\n",
       "      <td>2</td>\n",
       "      <td>00879, 03806</td>\n",
       "      <td>Q9Y255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>A8K855</td>\n",
       "      <td>2</td>\n",
       "      <td>02902, 06401</td>\n",
       "      <td>Q15506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>Q8N6M3</td>\n",
       "      <td>2</td>\n",
       "      <td>01400, 01887</td>\n",
       "      <td>Q09328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>Q9H4B8</td>\n",
       "      <td>2</td>\n",
       "      <td>02957, 04336</td>\n",
       "      <td>Q9BTN0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>Q9H4A9</td>\n",
       "      <td>2</td>\n",
       "      <td>02957, 04336</td>\n",
       "      <td>Q9BTN0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2055 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     missing_acc  number_of_complexes           assoc_complex_ids  \\\n",
       "0         Q13137                    3         00806, 06259, 06729   \n",
       "1         Q9NXF1                    4  00441, 03649, 06152, 06210   \n",
       "2         Q8NBF6                    2                02970, 05289   \n",
       "3         P80108                    2                02970, 05289   \n",
       "4         Q96LR4                    2                02970, 05289   \n",
       "...          ...                  ...                         ...   \n",
       "2050      Q9Y3B1                    2                00879, 03806   \n",
       "2051      A8K855                    2                02902, 06401   \n",
       "2052      Q8N6M3                    2                01400, 01887   \n",
       "2053      Q9H4B8                    2                02957, 04336   \n",
       "2054      Q9H4A9                    2                02957, 04336   \n",
       "\n",
       "     associated_identifiers_in_expected_related_huMAP3_complexes  \n",
       "0                                                Q9NVV4           \n",
       "1                        Q9Y4W2, Q5SY16, Q9H4L4, Q9BV38           \n",
       "2                                        Q6UXD5, Q9UBG0           \n",
       "3                                        Q6UXD5, Q9UBG0           \n",
       "4                                        Q6UXD5, Q9UBG0           \n",
       "...                                                 ...           \n",
       "2050                                             Q9Y255           \n",
       "2051                                             Q15506           \n",
       "2052                                             Q09328           \n",
       "2053                                             Q9BTN0           \n",
       "2054                                             Q9BTN0           \n",
       "\n",
       "[2055 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disappearing_identified_with_STRversion_dict = {k:(', ').join(v) for k,v in disappearing_identified_with_dict.items()}\n",
    "df_related_going_disappearing = pd.DataFrame.from_dict(\n",
    "    disappearing_identified_with_STRversion_dict,orient='index').reset_index()\n",
    "df_related_going_disappearing.columns = ['missing_acc', 'associated_identifiers_in_expected_related_huMAP3_complexes']\n",
    "# add the column with the sizes of the complexes seen \n",
    "df_related_going_disappearing.insert(1, 'number_of_complexes', df_related_going_disappearing['missing_acc'].map(disappeared_total_complexes_dict))\n",
    "# add the column with the ids of the complexes seen \n",
    "v2_complexes_with_disappearing_STRversion_dict = {k:(', ').join(v).replace('HuMAP2_','') for k,v in v2_complexes_with_disappearing_dict.items()} # in interest of streamlining also remove `HuMAP2_` that occurs on all complex ids\n",
    "df_related_going_disappearing.insert(2, 'assoc_complex_ids', df_related_going_disappearing['missing_acc'].map(v2_complexes_with_disappearing_STRversion_dict))\n",
    "'''\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(df_related_going_disappearing)\n",
    "'''\n",
    "df_related_going_disappearing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e33bbd1-463a-4a87-b41b-7351b08c6477",
   "metadata": {},
   "source": [
    "That is saved to csv by running the next cell and you can open that generated CSV file here or in Excel for looking over the whole set of details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3a94ab1-f7ad-4f77-9e9a-a5e62d3dd567",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_related_going_disappearing.to_csv(\"df_related_going_disappearing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3254f8d0-2a17-48e1-a6ef-dc2acca49e53",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "The script that was run above also highlighted those 'ubiquitous' ones that were in related complexes in hu.MAP 2.0 data and completely absent in hu.MAP 3.0 data. Running the next cell will show you that is a small fraction of the 2055 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb728257-3a9d-4cb7-b26f-db70c48ac8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gone_entirely_in_3_identified_via_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f7716-7411-4327-bb1a-0c30d70e23db",
   "metadata": {},
   "source": [
    "So winnowed to 151 by making things much more strict by saying couldn't be anywhere in the hu.MAP 3.0 data at all.\n",
    "\n",
    "This further emphasizes what was touched upon earlier about the the shifting or refinement that occurs between versions 2 and 3 of the hu.MAP data. Only 151 the 'ubiquitous' ones found in related complexes disappear entirely in the hu.MAP 3.0 data. The other 1904 of the 2055 'ubiquitous' ones found in related complexes at least show up in the hu.MAP 3.0 data somewhere. \n",
    "\n",
    "Before we go on to look at how what has been identified as 'ubiquitous' yet missing from related, let's do some steps like done with the larger group so these 151 can be perused more easily and/or in combined forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41125042-79f9-43cc-9085-9eb8511253b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'gone_entirely_in_3_identified_via_dict' (dict) to file 'gone_entirely_in_3_identified_via_dict.txt'.\n",
      "Writing 'gone_entirely_in_3_total_complexes_dict' (dict) to file 'gone_entirely_in_3_total_complexes_dict.txt'.\n"
     ]
    }
   ],
   "source": [
    "%store gone_entirely_in_3_identified_via_dict >gone_entirely_in_3_identified_via_dict.txt\n",
    "%store gone_entirely_in_3_total_complexes_dict >gone_entirely_in_3_total_complexes_dict.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81c70f00-1e2e-4d04-bcef-7c46c7de14f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_acc</th>\n",
       "      <th>number_of_complexes</th>\n",
       "      <th>assoc_complex_ids</th>\n",
       "      <th>associated_identifiers_in_expected_related_huMAP3_complexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q9NXF1</td>\n",
       "      <td>4</td>\n",
       "      <td>00441, 03649, 06152, 06210</td>\n",
       "      <td>Q9Y4W2, Q5SY16, Q9H4L4, Q9BV38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPECIAL_HGNC15792</td>\n",
       "      <td>3</td>\n",
       "      <td>02624, 03560, 00611</td>\n",
       "      <td>Q8TBG4, Q04446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O75533</td>\n",
       "      <td>4</td>\n",
       "      <td>02124, 02351, 02806, 05865</td>\n",
       "      <td>Q9BWJ5, Q7RTV0, Q13435, Q15393, Q9Y3B4, Q15427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q5JNZ5</td>\n",
       "      <td>3</td>\n",
       "      <td>01493, 02859, 05267</td>\n",
       "      <td>Q02539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O76021</td>\n",
       "      <td>2</td>\n",
       "      <td>00300, 06948</td>\n",
       "      <td>Q5JTH9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Q6P996</td>\n",
       "      <td>3</td>\n",
       "      <td>01309, 01760, 02725</td>\n",
       "      <td>Q9Y6A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>O75396</td>\n",
       "      <td>2</td>\n",
       "      <td>00854, 02979</td>\n",
       "      <td>Q8WV48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Q9BVI4</td>\n",
       "      <td>4</td>\n",
       "      <td>00135, 01287, 02156, 04976</td>\n",
       "      <td>P78316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Q8N4H0</td>\n",
       "      <td>2</td>\n",
       "      <td>02522, 04359</td>\n",
       "      <td>O95239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Q9UBN1</td>\n",
       "      <td>2</td>\n",
       "      <td>00521, 06580</td>\n",
       "      <td>Q6ZPD9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           missing_acc  number_of_complexes           assoc_complex_ids  \\\n",
       "0               Q9NXF1                    4  00441, 03649, 06152, 06210   \n",
       "1    SPECIAL_HGNC15792                    3         02624, 03560, 00611   \n",
       "2               O75533                    4  02124, 02351, 02806, 05865   \n",
       "3               Q5JNZ5                    3         01493, 02859, 05267   \n",
       "4               O76021                    2                00300, 06948   \n",
       "..                 ...                  ...                         ...   \n",
       "146             Q6P996                    3         01309, 01760, 02725   \n",
       "147             O75396                    2                00854, 02979   \n",
       "148             Q9BVI4                    4  00135, 01287, 02156, 04976   \n",
       "149             Q8N4H0                    2                02522, 04359   \n",
       "150             Q9UBN1                    2                00521, 06580   \n",
       "\n",
       "    associated_identifiers_in_expected_related_huMAP3_complexes  \n",
       "0                       Q9Y4W2, Q5SY16, Q9H4L4, Q9BV38           \n",
       "1                                       Q8TBG4, Q04446           \n",
       "2       Q9BWJ5, Q7RTV0, Q13435, Q15393, Q9Y3B4, Q15427           \n",
       "3                                               Q02539           \n",
       "4                                               Q5JTH9           \n",
       "..                                                 ...           \n",
       "146                                             Q9Y6A1           \n",
       "147                                             Q8WV48           \n",
       "148                                             P78316           \n",
       "149                                             O95239           \n",
       "150                                             Q6ZPD9           \n",
       "\n",
       "[151 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gone_entirely_in_3_identified_via_STRversion_dict = {k:(', ').join(v) for k,v in gone_entirely_in_3_identified_via_dict.items()}\n",
    "df_related_gone_entirely_in_3 = pd.DataFrame.from_dict(\n",
    "    gone_entirely_in_3_identified_via_STRversion_dict,orient='index').reset_index()\n",
    "df_related_gone_entirely_in_3.columns = ['missing_acc', 'associated_identifiers_in_expected_related_huMAP3_complexes']\n",
    "# add the column with the sizes of the complexes seen \n",
    "df_related_gone_entirely_in_3.insert(1, 'number_of_complexes', df_related_gone_entirely_in_3['missing_acc'].map(gone_entirely_in_3_total_complexes_dict))\n",
    "# add the column with the ids of the complexes seen \n",
    "gone_v2_complexes_with_disappearing_STRversion_dict = {k:(', ').join(v).replace('HuMAP2_','') for k,v in v2_complexes_dict_for_gone_in_3 .items()} # in interest of streamlining also remove `HuMAP2_` that occurs on all complex ids\n",
    "df_related_gone_entirely_in_3.insert(2, 'assoc_complex_ids', df_related_gone_entirely_in_3['missing_acc'].map(gone_v2_complexes_with_disappearing_STRversion_dict))\n",
    "'''\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(df_related_gone_entirely_in_3)\n",
    "'''\n",
    "df_related_gone_entirely_in_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "132c60b9-a6ba-47c9-b49e-dfd6d8e5518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_related_gone_entirely_in_3.to_csv(\"df_related_gone_entirely_in_3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc585408-42e3-4223-a9af-eca9e7ab5989",
   "metadata": {},
   "source": [
    "Open that file to review it more easily.\n",
    "\n",
    "The analysis with the script limited things to those proteins in complexes where you can see related, 'ubiquitous' proteins that show up in version 3 data without proteins version 2 data revealed as associated. Whether or not those proteins showed up at al in version 3 or not. But what if look at things that seen in version 2 data but gone in version 3 without regards to whether there's proteins that look associated in version 2 or not. Meaning in a practical sense proteins that only need to show up once iin version 2, but are gone entirely in version 3 data.\n",
    "\n",
    "I do this not only because your protein might be in such a group, but also because it gives a better sense of how many of the 'disappearing' ones we've already revealed by the approach above that focused on expecting to see related proteins, based on association version 2 data, in the complexes seen in version 3 data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452a0157-c61d-472f-892a-582515abdff9",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "**Trying to see if get same identifiers if just took what was in hu.MAP2 data and gone in version 3 data.**  \n",
    "\n",
    "Run next cell to use set substraction to collect what remains from hu.MAP 2.0 data if you subract out everything seen in hu.MAP 3.0 data, and then in subsequent cell(s) see if same as keys in `gone_entirely_in_3_identified_via_dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9bf204a-896c-4e87-a7d3-3c37ff4e86d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directly_determined_gone_missing_accs = set(v2data_info_as_df['Uniprot_ACCs']) - (set(v3data_info_as_df['Uniprot_ACCs']))\n",
    "len(directly_determined_gone_missing_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec47f25-662a-4b32-b77f-37b755d01400",
   "metadata": {},
   "source": [
    "This is a bit bigger than 151 that we mentioned being gone entirely in version 3 data, but actually not by a lot. Nearly only double.  \n",
    "And that will include the 151 we discussed above because I had restricted 'ubiquitous' to having be define by two ore more complexes. We can show that by a check to see if that group includes the 151 by running the next cell that uses more of Python's set math:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b578a7f9-236d-42c2-a3ce-c7785a674069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gone_entirely_in_3_set.issubset(directly_determined_gone_missing_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cdaf24-497e-41fd-8fa0-34582ae9eeac",
   "metadata": {},
   "source": [
    "That's true, as expected.\n",
    "\n",
    "So how many have we expanded here sepcifically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60fe6ebe-e6ef-4a67-b785-2a8f4aed4ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(directly_determined_gone_missing_accs - gone_entirely_in_3_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f77141-0330-495f-8900-e93787d62e48",
   "metadata": {},
   "source": [
    "So indeed do get all the same 151 identifiers if just took what was in hu.MAP2 data and gone in version 3 data, plus presumably get additional 333 where not really 'ubiqutous' & disappearing from related complexes because complex the identifier has disappeared from is unique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ae7d33-e297-4169-a851-6c9d7e3de36e",
   "metadata": {},
   "source": [
    "So how do I prove that about these additional ones? They won't be among the dictionaries I already collected.  \n",
    "And ones among the 333 could be in more than one hu.MAP 2.0 complex because they can occur in un-related hu.MAP 2.0 complexes as long that identifier is gone in hu.MAP 3.0 data entirely.  \n",
    "So how to check that? The next three cells will set up a prelimanry examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bad161ce-b56d-483b-95e4-021599517994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_three_three_set = directly_determined_gone_missing_accs - gone_entirely_in_3_set\n",
    "len(three_three_three_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cda776f-a443-4b4c-b49b-f6672e0521d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'three_three_three_set' (set) to file 'three_three_three_set.txt'.\n"
     ]
    }
   ],
   "source": [
    "%store three_three_three_set >three_three_three_set.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7ddd15f-54cc-447d-af9c-1e63d5e459d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A0A075B759',\n",
      " 'A0A0G2JN01',\n",
      " 'A0M8Q6',\n",
      " 'A1Z1Q3',\n",
      " 'A2A3N6',\n",
      " 'A4FU69',\n",
      " 'A6NKF1',\n",
      " 'A6NKQ9',\n",
      " 'A6NLF2',\n",
      " 'A8MWD9',\n"
     ]
    }
   ],
   "source": [
    "!head three_three_three_set.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceab1ed0-8634-43c0-8040-f71b354a4bdd",
   "metadata": {},
   "source": [
    "Downloaded `three_three_three_set.txt to check and few and see if only occur in one or at least unrelated complexes as I expect.\n",
    "\n",
    "Some results:  \n",
    "`A6NKF1` only occurs once in hu.MAP 2.0 data and none in hu.MAP 3.0 data, which is consistent with what I expected.  \n",
    "It wouldn't be in the 151 group I had in `df_related_gone_entirely_in_3` and associated data because that was filtered out of the 'ubiquitous' group and to be in there in the first place, by the constraint I applied, it has to be in more than one complex.\n",
    "\n",
    "I know this isn't exhaustive and could be done better. However, at this point I see there is a fair amount of identifiers that either shift or get refined and a few hundred that don't show up at all in version 3 data. There isn't really a reason to look into the nature of these 333 so much for now.\n",
    "\n",
    "While it would be better if some don't disappear in version 3 while looking legitimate in version 2, and you may be unfortunate and have a protein in this group. Know though that this is the case for only a few hundred others and this is still an interesting dataset on a whole and seems informative at a biological level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12465e1f-61b2-41b2-9ddc-9c1cc6dcc52d",
   "metadata": {},
   "source": [
    "----------\n",
    "Enjoy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
