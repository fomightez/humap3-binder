{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e629ba-45b1-48e7-b97c-8fb990064dfa",
   "metadata": {},
   "source": [
    "# Making summary report notebooks & associated files for the hu.MAP3 complexes for many proteins\n",
    "\n",
    "See my [humap3-binder repo](https://github.com/fomightez/humap3-binder) and [humap3-utilities](https://github.com/fomightez/structurework/humap3-utilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d5493-8f48-4b60-97b2-812219359018",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "## Step #1: Preparation\n",
    "\n",
    "Make a list of the identifiers for the proteins of interest. You can use the official gene name or the UniProt identifiers for the protein. Either work. You'll put them below the line `%%%writefile Make_me_humap3_complex_reports_for_these.txt`, with one on each line. A demonstration is below and you may just want to run things witih that first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac42c30-1262-4718-ab4b-3fb33e3be7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Make_me_humap3_complex_reports_for_these.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile Make_me_humap3_complex_reports_for_these.txt\n",
    "FBL\n",
    "Q9NX24\n",
    "XRN1\n",
    "FakeName_for_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0727d93e-0878-4a75-8816-327670b34671",
   "metadata": {},
   "source": [
    "(Edit the above list to below the line `%%writefile Make_me_humap3_complex_reports_for_these.txt` have the UniProt extensions or the gene anmes for the corresponding proteins of interest, one on each line. If you are running this the first time, I suggest using the demostration identifiers to see if it all works and then edit and re-run according to suggestions below. Or just restart a new temporary session to get back to square one. If you have run this before though, edit above at this point to get making reports witih what you are interested in.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fd980d-006c-4638-876f-f30d882d5943",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "## Step #2: Running Snakemake to make the many summary reports and associated files\n",
    "\n",
    "Run snakemake and it will process the list of interesting ids to extract the information and make individual notebooks corresponding to hu.MAP 3.0 data for each protein. This will be very similar to running the basic notebooks in this series, but it will do it for all programmatically.  \n",
    "The file snakemake uses by default, named Snakefile, is already here and that is what will run when the next command is executed.\n",
    "It will take about a few minutes to complete if you are running the demonstration. If you edited things it will take longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5662a565-09b7-4d8d-ad44-5caa570b6597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading inline script metadata from `\u001b[36mcomplexes_rawCSV_to_df.py\u001b[39m`\n",
      "\u001b[2K\u001b[37mâ ™\u001b[0m \u001b[2m                                                                              \u001b[0m\n",
      "\n",
      "Warning: Identifier \u001b[32m'FakeName_for_testing'\u001b[0m\u001b[32m' not found in the reference columns \u001b[0m\n",
      "\u001b[32m'\u001b[0mUniprot_ACCs' or \u001b[32m'genenames'\u001b[0m.\n",
      "That identifier \u001b[32m'FakeName_for_testing'\u001b[0m will be removed from consideration here.\n",
      "Removed \u001b[1;36m1\u001b[0m identifiers total\n",
      "Processing \u001b[1;36m3\u001b[0m identifiers to examine the incolved complexes.\n",
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[31mMissingInputException in rule read_table_and_create_py in file /home/jovyan/notebooks/id_2_humap3_complexes_snakefile, line 427:\n",
      "Missing input files for rule read_table_and_create_py:\n",
      "    output: Summary_report_humap3_data_for_FBL.py, Summary_report_humap3_data_for_Q9NX24.py, Summary_report_humap3_data_for_XRN1.py\n",
      "    affected files:\n",
      "        hu.MAP3.0_complexes_wConfidenceScores_total15326_wGenenames_20240922.csv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake -s id_2_humap3_complexes_snakefile --cores 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3e9d1-4740-4c91-ae20-fc9df5ba3ce8",
   "metadata": {},
   "source": [
    "**Step #4:** Verify the Jupyter notebooks with the reports were generated.  \n",
    "If you ran the demo ones, you can click [here](???????????????.ipynb) to open one of them.  For the others...  \n",
    "You can go to the dashboard and see the ouput of running snakemake. To do that click on the Jupyter logo in the upper left top of this notebook and on that page you'll look in  the notebooks directory and you should see files that begin with `interactions_report_` and end with `.ipynb`. You can examine some of them to insure all is as expected.\n",
    "\n",
    "If things seem to be working and you haven't run your data yet, run `!snakemake -s id_2_humap3_complexes_snakefile --cores 1 clean` in a cell to reset things, and then edit the list above below `%%writefile Make_me_humap3_complex_reports_for_these.txt` to have the identifiers of interest each on a line, run that edited cell, and then run the `!snakemake -s id_2_humap3_complexes_snakefile --cores 1` step above, again.\n",
    "\n",
    "Download anything useful you make. In particular the files with the `.ipynb` extension.\n",
    "\n",
    "NOT YET IMPLEMENTED BELOW.....DISREGARD ALL THE REST FOR NOW...   \n",
    "**Step #5:** If this was anything other than the demonstration run, download the archive containing all the Jupyter notebooks bundled together.  \n",
    "NOT YET IMPLEMENTED BELOW.....DISREGARD ALL THE REST FOR NOW.....For ease in downloading, all the created notebooks have been saved as a compressed archive so that you only need to retrieve and keep track of one file. The file you are looking for begins with `interactions_report_nbs` in front of a date/time stamp and ends with `.tar.gz`. The snakemake run will actually highlight this archive towards the very bottom of the run, following the words 'Be sure to download'.  \n",
    "**Download that file from this remote, temporary session to your local computer.** You should see this archive file ending in `.tar.gz` on the dashboard. Toggle next to it to select it and then select `Download` to bring it from the remote Jupyterhub session to your computer. If you don't retieve that file and the session ends, you'll need to re-run to get the results again.\n",
    "\n",
    "You should be able to unpack that archive using your favorite software to extract compressed files. If that is proving difficult, you can always reopen a session like you did to run this series of notebooks and upload the archive and then run the following command in a Jupyter notebook cellk to unpack it:\n",
    "\n",
    "```bash\n",
    "!tar xzf interactions_report_nbs*\n",
    "```\n",
    "\n",
    "(If you are running that command on the command line, leave off the exclamation mark.)\n",
    "You can then examine the files in the session or download the individual Jupyter notebooks similar to the advice on how to download the archive given above.\n",
    "\n",
    "In the next notebook in this series, [MAYBE eventually???](Not_yet_made.ipynb)), I work through how to make the reports more human readable by.....?.\n",
    "\n",
    "If this notebook has you interested in learning more about Snakemake as workflow management software, I did use a somewhat related, yet distinct and simpler workflow, to provide more background to using Snakemake in the notebook 'Making multiple interface-reporting dataframes for several structures using snakemake' available when you go [here](https://github.com/fomightez/pdbepisa-binder) and click `launch binder`. That Jupyter notebook also suggests further resources for learning to write Snakemake workflows.\n",
    "\n",
    "-----\n",
    "\n",
    "Please continue on with the next notebook in this series, [MAYBE eventually???](Not_yet_made.ipynb).\n",
    "\n",
    "\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86904f97-b5c1-47dc-8c1b-e95b34ae7411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}