{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e629ba-45b1-48e7-b97c-8fb990064dfa",
   "metadata": {},
   "source": [
    "# Highlight differences between hu.MAP 2.0 and hu.MAP 3.0 data\n",
    "\n",
    "This notebook is primarily an intermediate to introducing to the next notebook in this series, ['Using snakemake to highlight differences between hu.MAP 2.0 and hu.MAP 3.0 data for multiple identifiers'](Using_snakemake_to_highlight_differences_between_hu.MAP2_and_hu.MAP3_data_for_multiple_indentifiers..ipynb). Here the steps to see the difference between complexes represented in hu.MAP 2.0 and hu.MAP 3.0 data is done with one example. You can change the hard-coded values here to investigate the differences for others. However, chances are you are interested in the differnces for several genes/proteins. In ['Using snakemake to highlight differences between hu.MAP 2.0 and hu.MAP 3.0 data for multiple identifiers'](Using_snakemake_to_highlight_differences_between_hu.MAP2_and_hu.MAP3_data_for_multiple_indentifiers.ipynb), it will work through the steps to run a Snakemake workflow to process the identifiers for many proteins/genes to generate summary reports highlighting differences in human complexes reported in hu.MAP 2.0 vs. hu.MAP 3.0 data. And that is more likely where you want to invest your time. You may want to quickly san the notebook below though to see the types of reports you'll expect when you give the snakemake file your list of identifiers. And with more details here it may help you troubleshoot such snakemake-generated reports. \n",
    "\n",
    "This effort just is meant to highlight possible differences. There is some approximating done to determine possible corresponding complexes that inherently brings in some possible judgement calls. You'll need to explore the results from each for yourself to compare in depth. The hu.MAP 2.0 data can be explored in sessions launched from my [humap2-binder repo](https://github.com/fomightez/humap2-binder)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d5493-8f48-4b60-97b2-812219359018",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "## Step #1: Preparation\n",
    "\n",
    "The preparation parallels the notebooks ['Use of hu.MAP 3.0 data programmatically with Python, taking advantage of Jupyter features'](Working_with_hu.MAP3_data_with_Python_in_Jupyter_Basics.ipynb) and ['Use of hu.MAP 2.0 data programmatically with Python, taking advantage of Jupyter features'](Working_with_hu.MAP3_data_with_Python_in_Jupyter_Basics.ipynb), and so see them for more insight.\n",
    "\n",
    "Get the data for hu.MAP 2.0 and hu.MAP 3.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c80a36fc-fbb5-4980-aea5-25872d5aeb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  502k  100  502k    0     0  1870k      0 --:--:-- --:--:-- --:--:-- 1875k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1243k  100 1243k    0     0  2426k      0 --:--:-- --:--:-- --:--:-- 2424k\n"
     ]
    }
   ],
   "source": [
    "!curl -OL https://raw.githubusercontent.com/fomightez/humap2-binder/refs/heads/main/additional_nbs/standardizing_initial_data/humap2_complexes_20200809InOrderMatched.csv\n",
    "!curl -OL https://raw.githubusercontent.com/fomightez/humap3-binder/refs/heads/main/additional_nbs/standardizing_initial_data/hu.MAP3.0_complexes_wConfidenceScores_total15326_wGenenames_20240922InOrderMatched.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6992d046-e280-4ddd-b4a6-e18906df959c",
   "metadata": {},
   "source": [
    "Get an accessory scripts for adding information about the proteins in the complexes & collecting differences between two versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d08cff4-c9ad-4065-8246-38e58b71f513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2893  100  2893    0     0  16392      0 --:--:-- --:--:-- --:--:-- 16344\n"
     ]
    }
   ],
   "source": [
    "!curl -OL https://raw.githubusercontent.com/fomightez/structurework/refs/heads/master/humap3-utilities/make_lookup_table_for_extra_info4complexes.py\n",
    "!curl -OL https://raw.githubusercontent.com/fomightez/structurework/refs/heads/master/humap3-utilities/two_comp_three_details_plus_table.ipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf301a-75c8-4faa-9c2e-028d7cb4bc55",
   "metadata": {},
   "source": [
    "##### Put the data on the complexes into Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa6f2f0f-2231-4d35-b5c7-08d89d5aed2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1007  100  1007    0     0   3547      0 --:--:-- --:--:-- --:--:--  3558\n"
     ]
    }
   ],
   "source": [
    "!curl -OL https://raw.githubusercontent.com/fomightez/structurework/refs/heads/master/humap3-utilities/complexes_rawCSV_to_df.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84223330-171f-4ab6-8a64-053c5492a4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading inline script metadata from `\u001b[36mcomplexes_rawCSV_to_df.py\u001b[39m`\n",
      "\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2m                                                                              \u001b[0mReading inline script metadata from `\u001b[36mcomplexes_rawCSV_to_df.py\u001b[39m`\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2m                                                                              \u001b[0m"
     ]
    }
   ],
   "source": [
    "!uv run complexes_rawCSV_to_df.py humap2_complexes_20200809InOrderMatched.csv\n",
    "import pandas as pd\n",
    "rd2_df = pd.read_pickle('raw_complexes_pickled_df.pkl')\n",
    "!uv run complexes_rawCSV_to_df.py hu.MAP3.0_complexes_wConfidenceScores_total15326_wGenenames_20240922InOrderMatched.csv\n",
    "rd3_df = pd.read_pickle('raw_complexes_pickled_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21e55a6-7064-430a-bacd-c9fbb7d2f9fe",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703a5e9d-b2a9-4085-8fde-3774fc6b5bbf",
   "metadata": {},
   "source": [
    "## Analyze complexes in hu.MAP 2.0 vs. hu.MAP 3.0 for a protein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73616bb2-04f8-44ca-b6dc-2220c229eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"ROGDI\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a71f0-4543-4f4c-8f8e-5a91b2866a1b",
   "metadata": {},
   "source": [
    "Get complexes that protein is in in both sets of data, adding extra information like done in earlier notebooks.  \n",
    "Then use that to make a summary table for change from version 2.0 to version 3.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1251c0d9-5156-4d99-ab7d-ec50bb19d4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       HuMAP2_ID  Confidence Uniprot_ACCs genenames\n",
      "6   HuMAP2_01834           3       Q9Y4E6      WDR7\n",
      "7   HuMAP2_03388           2       Q9Y485     DMXL1\n",
      "8   HuMAP2_03388           2       Q9GZN7     ROGDI\n",
      "9   HuMAP2_03388           2       Q8TDJ6     DMXL2\n",
      "10  HuMAP2_03388           2       Q9Y4E6      WDR7\n",
      " \n",
      "          HuMAP3_ID  ComplexConfidence Uniprot_ACCs genenames\n",
      "297  huMAP3_13872.1                  6       Q8NI08     NCOA7\n",
      "298  huMAP3_13872.1                  6       Q8TDJ6     DMXL2\n",
      "299  huMAP3_13872.1                  6       Q9GZN7     ROGDI\n",
      "300  huMAP3_13872.1                  6       Q9Y485     DMXL1\n",
      "301  huMAP3_13872.1                  6       Q9Y4E6      WDR7\n"
     ]
    }
   ],
   "source": [
    "%run two_comp_three_details_plus_table.ipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e874e9c1-3330-4fdd-9a73-5886a06e2d91",
   "metadata": {},
   "source": [
    "That above should be a summary table quickly giving a sense of the improvement in 3.0 data. (Or lack thereof, if yo have substituted with your protein of interest?)\n",
    "\n",
    "Despite general improvment, I noticed some information present in version 2.0 complexes went missing in complexes reported in version 3.0.\n",
    "    \n",
    "#### Check for disappearing proteins in complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4886c09-efbe-4c9e-b0fe-fa34d1c0d82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Disappearing Items between Hu.MAP2.0 and Hu.MAP3.0 data:\n",
      "\n",
      "HuMAP2 ID: HuMAP2_01834 -> HuMAP3 ID: huMAP3_12042.1\n",
      "Total items in HuMAP2: 5\n",
      "Total items in HuMAP3: 56\n",
      "Percent of items lost: 20.00%\n",
      "UniProt ACCs Lost From Corresponding Complex:\n",
      "  - P50993 (AND NOT IN ANY OTHER Hu.MAP3.0 ROGDI-complexes!!!)\n",
      "\n",
      "HuMAP2 ID: HuMAP2_03388 -> HuMAP3 ID: huMAP3_10511.1\n",
      "Total items in HuMAP2: 4\n",
      "Total items in HuMAP3: 35\n",
      "Percent of items lost: 25.00%\n",
      "UniProt ACCs Lost From Corresponding Complex:\n",
      "  - Q8TDJ6 (But present in other, ROGDI-related Hu.MAP3.0 complexes)\n"
     ]
    }
   ],
   "source": [
    "# Make sure nothing present in HuMAP2 data disappeared in huMAP3 data\n",
    "# Function to compare UniProt ACCs between HuMAP2 and HuMAP3\n",
    "def check_disappearing_items(df_correspondences, df2_expanded, df3_expanded):\n",
    "    # Tracking disappearing items\n",
    "    disappearing_items = []\n",
    "    \n",
    "    for _, correspondence in df_correspondences.iterrows():\n",
    "        humap2_id = correspondence['HuMAP2_ID']\n",
    "        humap3_id = correspondence['HuMAP3_ID']\n",
    "        \n",
    "        # Get UniProt ACCs for this HuMAP2 group\n",
    "        humap2_accs = set(df2_expanded[df2_expanded['HuMAP2_ID'] == humap2_id]['Uniprot_ACCs'])\n",
    "        \n",
    "        # Get UniProt ACCs for this HuMAP3 group\n",
    "        humap3_accs = set(df3_expanded[df3_expanded['HuMAP3_ID'] == humap3_id]['Uniprot_ACCs'])\n",
    "        \n",
    "        # Find items in HuMAP2 that are not in HuMAP3\n",
    "        lost_items = humap2_accs - humap3_accs\n",
    "        \n",
    "        if lost_items:\n",
    "            disappearing_items.append({\n",
    "                'HuMAP2_ID': humap2_id,\n",
    "                'HuMAP3_ID': humap3_id,\n",
    "                'lost_items': lost_items,\n",
    "                'total_humap2_items': len(humap2_accs),\n",
    "                'total_humap3_items': len(humap3_accs),\n",
    "                'percent_lost': len(lost_items) / len(humap2_accs) * 100 if humap2_accs else 0\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame for easy analysis\n",
    "    df_disappearing = pd.DataFrame(disappearing_items)\n",
    "    \n",
    "    # Display results\n",
    "    global something_dropped_completely\n",
    "    something_dropped_completely = False\n",
    "    if not df_disappearing.empty:\n",
    "        print(\"\\nDisappearing Items between Hu.MAP2.0 and Hu.MAP3.0 data:\")\n",
    "        for _, row in df_disappearing.iterrows():\n",
    "            print(f\"\\nHuMAP2 ID: {row['HuMAP2_ID']} -> HuMAP3 ID: {row['HuMAP3_ID']}\")\n",
    "            print(f\"Total items in HuMAP2: {row['total_humap2_items']}\")\n",
    "            print(f\"Total items in HuMAP3: {row['total_humap3_items']}\")\n",
    "            print(f\"Percent of items lost: {row['percent_lost']:.2f}%\")\n",
    "            print(\"UniProt ACCs Lost From Corresponding Complex:\")\n",
    "            for item in row['lost_items']:\n",
    "                dropped_completely = (item not in df3_expanded['Uniprot_ACCs'].to_list())\n",
    "                if dropped_completely:\n",
    "                    print(f\"  - {item} (AND NOT IN ANY OTHER Hu.MAP3.0 {search_term}-complexes!!!)\")\n",
    "                    something_dropped_completely = True\n",
    "                else:\n",
    "                    print(f\"  - {item} (But present in other, {search_term}-related Hu.MAP3.0 complexes)\")\n",
    "        \n",
    "        # Optional: Save to CSV\n",
    "        df_disappearing.to_csv('disappearing_items.csv', index=False)\n",
    "        \n",
    "        return df_disappearing, something_dropped_completely\n",
    "    else:\n",
    "        print(\"\\nNo disappearing items found between HuMAP2 and HuMAP3.\")\n",
    "        return None, something_dropped_completely\n",
    "\n",
    "# Call the function\n",
    "disappearing_df, something_dropped_completely = check_disappearing_items(df_correspondences, df2_expanded, df3_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "924889b2-8e87-44a8-aee0-0b4e0605ba4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hu.MAP2.0-Majority Complex Members Disappearing in Hu.MAP3.0 data:\n",
      "NONE\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Also make sure nothing that is in the majority of complexes in hu.MAP 2.0 data disappears entirely from hu.MAP 3.0 data.\n",
    "# That can only occur as the case if `something_dropped_completely`, that we've already check on, is True\n",
    "majority_item_dropped_completely = False #set up by declaring false\n",
    "if something_dropped_completely:\n",
    "    # collect information on what identifiers occur in the majority of complexes in hu.MAP 2.0 data\n",
    "    # the search term should always be present and can thus serve as a sanity check for this collection\n",
    "    majority_identifiers = []\n",
    "    def find_majority_uniprot_accs(df):\n",
    "        # Group by HuMAP2_ID and get unique Uniprot_ACCs for each complex\n",
    "        complex_accs = df.groupby('HuMAP2_ID')['Uniprot_ACCs'].unique()\n",
    "        \n",
    "        # Count total number of unique complexes\n",
    "        total_complexes = len(complex_accs)\n",
    "        \n",
    "        # Flatten and count occurrences of each Uniprot ACC across complexes\n",
    "        all_accs = df['Uniprot_ACCs'].tolist()\n",
    "        acc_counts = pd.Series(all_accs).value_counts()\n",
    "        \n",
    "        # Find ACCs that appear in more than 50% of complexes\n",
    "        majority_accs = acc_counts[acc_counts >= 0.51 * total_complexes].index.tolist()\n",
    "        \n",
    "        return majority_accs\n",
    "    if find_majority_uniprot_accs(df2_expanded):\n",
    "        majority_identifiers = find_majority_uniprot_accs(df2_expanded)\n",
    "    # Now check none of those `majority_identifiers` match the disappearing ones dropped completely\n",
    "    print(\"\\nHu.MAP2.0-Majority Complex Members Disappearing in Hu.MAP3.0 data:\")\n",
    "    for item in list(set.union(*disappearing_df['lost_items'])): # note `list(set.union(*disappearing_df['lost_items']))` gets the unique set members from the 'lost_items' column\n",
    "        if item in majority_identifiers:\n",
    "            majority_item_dropped_completely = (item not in df3_expanded['Uniprot_ACCs'].to_list())\n",
    "            if majority_item_dropped_completely:\n",
    "                print(f\"  - {item} IS IN MAJORITY OF Hu.MAP2.0 COMPLEXES YET NOT IN ANY Hu.MAP3.0 {search_term}-complexes!!! (PERHAPS CONCERNING?)\")\n",
    "                majority_item_dropped_completely = True\n",
    "    if majority_item_dropped_completely == False:\n",
    "        print(\"NONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3e9d1-4740-4c91-ae20-fc9df5ba3ce8",
   "metadata": {},
   "source": [
    " You can change the hard-coded values here to investigate the differences for others. However, chances are you are interested in the differnces for several genes/proteins, and so you'll want to first check out the next notebook in this series, ['Using snakemake to highlight differences between hu.MAP 2.0 and hu.MAP 3.0 data for multiple identifiers'](Using_snakemake_to_highlight_differences_between_hu.MAP2_and_hu.MAP3_data_for_multiple_indentifiers.ipynb). That notebook will work through the steps to run a Snakemake workflow to process the identifiers for many proteins/genes to generate summary reports highlighting differences in human complexes reported in hu.MAP 2.0 vs. hu.MAP 3.0 data.\n",
    " \n",
    "-----\n",
    "\n",
    "Enjoy!\n",
    "\n",
    "See my [humap3-binder repo](https://github.com/fomightez/humap3-binder) and [humap3-utilities](https://github.com/fomightez/structurework/humap3-utilities) for related information & resources for this notebook.\n",
    "\n",
    "\n",
    "\n",
    "-----\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
